# routes/service_routes.py

import json
import logging
from fastapi import APIRouter, Path, HTTPException, Body, Depends
from models.templates import UserPrompt
from services.service_manager import AsistenteDeServicioAsync
from services.data_extractor import ExtractorDeInformacionAsync
from fastapi.responses import JSONResponse
import asyncio

service_router = APIRouter()

service_instances = {}

def get_service_assistant(service: str, service_type: str) -> AsistenteDeServicioAsync:
    key = f"{service}_{service_type}"
    if key in service_instances:
        return service_instances[key]
    else:
        assistant = AsistenteDeServicioAsync(service=service, service_type=service_type)
        service_instances[key] = assistant
        return assistant

@service_router.post("/api/v1/request-service/{service}/{service_type}", tags=["‚ú® AI Service Requests"])
async def handle_service_request(service: str = Path(..., description="Categor√≠a del servicio requerido"), service_type: str = Path(..., description="Tipo de servicio requerido"), user_prompt: UserPrompt = Body(...), asistente: AsistenteDeServicioAsync = Depends(get_service_assistant)):
    """
    üõéÔ∏è **Endpoint de Solicitud de Servicio**
    
    Este endpoint permite a los usuarios solicitar diferentes tipos de servicios clasificados por categor√≠a y tipo. Utiliza un modelo de lenguaje entrenado y directrices espec√≠ficas para proporcionar respuestas personalizadas y eficaces.
    
    ### Par√°metros:
    - **service**: La categor√≠a del servicio que el usuario desea solicitar. Ejemplos: 'travel', 'catering'.
    - **service_type**: El tipo de servicio dentro de la categor√≠a, puede ser 'profesional' o 'personal'.
    - **user_prompt**: Un objeto que contiene el ID del usuario y su entrada de texto, representando la solicitud de servicio.
    
    ### Respuesta:
    - **response**: Un objeto JSON con la respuesta generada por el asistente de servicio, adaptada al tipo y categor√≠a de solicitud.
    """
    max_retries = 3  # N√∫mero m√°ximo de intentos
    retry_delay = 2  # Segundos de espera entre intentos

    for attempt in range(max_retries):
        try:
            respuesta_obj = await asistente.enviar_peticion(user_prompt.user_id, user_prompt.user_input)
            logging.info(f"Respuesta recibida: {respuesta_obj}")
            if 'error' in respuesta_obj:
                raise Exception(respuesta_obj['error'])
            return JSONResponse(content=respuesta_obj)  # Retorna la respuesta si tiene √©xito
        except json.JSONDecodeError as e:
            logging.error(f'Error de decodificaci√≥n JSON en intento {attempt + 1}: {str(e)}')
            if attempt < max_retries - 1:  # Verifica si no es el √∫ltimo intento
                await asyncio.sleep(retry_delay)  # Espera antes del pr√≥ximo intento
            else:
                raise HTTPException(status_code=500, detail=f'Error de decodificaci√≥n JSON: {str(e)}')
        except Exception as e:
            logging.error(f'Intento {attempt + 1} fallido: {str(e)}')
            if attempt < max_retries - 1:  # Verifica si no es el √∫ltimo intento
                await asyncio.sleep(retry_delay)  # Espera antes del pr√≥ximo intento
            else:
                raise HTTPException(status_code=500, detail=str(e))  # Lanza error despu√©s del √∫ltimo intento

@service_router.post("/api/v1/extract-information", 
                     tags=["üîÆ AI Tools & Utilities"],
                     response_description="Extrae informaci√≥n estructurada de la conversaci√≥n del usuario y la devuelve en formato JSON.")
async def extract_information_endpoint(
        service: str = Body(..., description="El servicio asociado a la conversaci√≥n."),
        service_type: str = Body(..., description="Tipo de servicio que determinar√° el contexto de la extracci√≥n de informaci√≥n."),
        user_id: str = Body(..., description="ID √∫nico del usuario cuya conversaci√≥n se utilizar√° para la extracci√≥n de informaci√≥n.")
    ):
    """
    üí° **Endpoint de Extracci√≥n de Informaci√≥n**

    Este endpoint procesa la conversaci√≥n completa de un usuario, excluyendo los mensajes del sistema, utilizando un modelo de IA configurado para devolver informaci√≥n estructurada en formato JSON, basado en el tipo de servicio especificado.
    """
    try:
        # Utilizamos get_service_assistant para obtener la instancia del asistente
        assistant = get_service_assistant(service, service_type)
        
        # Verificar si existe una conversaci√≥n para el usuario
        conversation = assistant.conversaciones.get(user_id)
        if conversation is None:
            raise HTTPException(status_code=404, detail=f"Conversaci√≥n para el usuario '{user_id}' no encontrada")

        # Filtrar y excluir mensajes donde el rol es 'system'
        filtered_conversation = " ".join([message['content'] for message in conversation if message['role'] != 'system'])

        # Log de inicio de extracci√≥n
        logging.info(f"Extrayendo informaci√≥n para el servicio {service}, tipo {service_type} y el usuario {user_id}...")

        # Inicializaci√≥n y uso del extractor de informaci√≥n
        extractor = ExtractorDeInformacionAsync(service)
        extracted_information = await extractor.obtener_informacion(filtered_conversation, service_type)  # Pasar el travel_type correctamente
        # Log de informaci√≥n extra√≠da
        logging.info(f"Informaci√≥n extra√≠da para el servicio {service}, tipo {service_type} y el usuario {user_id} - Informaci√≥n: {extracted_information}")

        return JSONResponse(status_code=200, content=extracted_information)
    
    except Exception as e:
        # Log de error
        logging.error(f"Error al extraer informaci√≥n: {e}")
        raise HTTPException(status_code=500, detail=str(e))
